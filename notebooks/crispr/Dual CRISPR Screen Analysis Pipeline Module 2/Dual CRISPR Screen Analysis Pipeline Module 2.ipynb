{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual CRISPR Screen Analysis Pipeline\n",
    "# Module 2\n",
    "Amanda Birmingham, CCBB, UCSD (abirmingham@ucsd.edu)\n",
    "\n",
    "\n",
    "<a name=\"table-of-contents\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Review Goals](#review-goals)\n",
    "* [Set Up Environment](#set-up-environment)\n",
    "    * [Create Virtual Environment and Install Software](#create-virtual-environment-and-install-software)\n",
    "    * [Initialize Shared Variables and Functions](#initialize-shared-variables-and-functions)\n",
    "* [Normalize Raw Counts](#normalize-raw-counts)\n",
    "    * [Set Up Constants](#set-up-constants)\n",
    "    * [Set Up Helper Functions for Normalization](#set-up-helper-functions-for-normalization)\n",
    "    * [Normalize Across All Experiment Sets](#normalize-across-all-experiment-sets)\n",
    "* [Calculate Fold Changes](#calculate-fold-changes)\n",
    "    * [Calculate Fold Change and Log2 Fold Change Between Timepoints](#calculate-fold-change-and-log-fold-change-between-timepoints)\n",
    "    * TODO: [Calculate Fold Change and Log2 Fold Change Against Plasmid](#calculate-fold-change-and-log-fold-change-against-plasmid)\n",
    "* [Calculate Fitness and Pi Scores](#calculate-fitness-and-pi-scores)   \n",
    "* [Calculate Averages and P-Values for Gene Pair Metrics](#calculate-averages-and-p-values-for-gene-pair-metrics)\n",
    "* [Outstanding Questions](#outstanding-questions)\n",
    "    * [Aggregated Normalization](#aggregated-normalization)\n",
    "    * [Non-Targeting Control Collapse](#non-targeting-control-collapse)\n",
    "    * [Plasmid Fold-Changes](#plasmid-fold-changes)\n",
    "    * [Fitness Score P-Values](#fitness-score-p-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"review-goals\"></a>\n",
    "\n",
    "## Review goals\n",
    "\n",
    "The Workflow.pdf document provided by Dongxin Zhao on 02/11/2016 defines Module 2 this way:\n",
    "\n",
    "*Module 2: raw counts -> fitness and GI score* \n",
    "\n",
    "* Output normalized counts for each raw counts file\n",
    "* Output the fold change data \n",
    "    * Fold change VS d3: d14/d3 and d28/d3\n",
    "    * Fold change VS plasmid: d3/plasmid, d14/plasmid and d28/plasmid\n",
    "* Output fitness and its P-value for each time point\n",
    "    * Use Boutros’ method (Nature Method, 2011)\n",
    "* Output the GI π score and its P-value for each time point and sort\n",
    "\n",
    "On 03/17/2016, Dongxin also provided a methods.docx document that includes details on many of the above steps; information from this document will be included below with the affected step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"set-up-environment\"></a>\n",
    "\n",
    "## Set Up Environment\n",
    "\n",
    "<a name=\"create-virtual-environment-and-install-software\"></a>\n",
    "\n",
    "### Create Virtual Environment and Install Software\n",
    "\n",
    "In a terminal window, run\n",
    "<pre>\n",
    "cd Documents/Projects/Projects2016/mali_crispr/\n",
    "mkvirtualenv -p /usr/local/bin/python3 mali_cripsr_venv\n",
    "pip install --upgrade pip\n",
    "pip3 install pandas\n",
    "pip3 install scipy\n",
    "pip3 install jupyter\n",
    "jupyter notebook\n",
    "</pre>\n",
    "\n",
    "Then open this notebook.\n",
    "\n",
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"initialize-shared-variables-and-functions\"></a>\n",
    "\n",
    "### Initialize Shared Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below is 80-character ruler to ensure code lines don't get too long\n",
    "\"123456789012345678901234567890123456789012345678901234567890123456789012345678\"\n",
    "g_mod1_output_dir = (\"/Users/Birmingham/Projects/20160210_mali_crispr/real_data\")\n",
    "g_mod1_output_suffix = \"_raw.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"normalize-raw-counts\"></a>\n",
    "\n",
    "\n",
    "## Normalize Raw Counts\n",
    "\n",
    "methods.docx specifies that normalization should be performed by the following approach:\n",
    "![](images/2016-03-18_9.48.48.png)\n",
    "\n",
    "I contacted Dongxin for clarification on several points.  He wrote back:\n",
    "\n",
    ">(1) Each day is a separate experiment. For example, i = \"ADA_chr20_43280245__ABL1_chr9_133589790\" and j = day 3. [snip /]\n",
    "\n",
    ">(2) Each construct must be separate. For example, \"ADA_chr20_43280245__ABL1_chr9_133589790\" and \"ADA_chr20_43280245__ABL1_chr9_133738283\" are two different pairs because the two ABL gRNAs target to different positions. And \"ADA_chr20_43280245__ABL1_chr9_133589790\" is different from \"ABL1_chr9_133589790__ADA_chr20_43257696\", and different from \"\n",
    "ABL1_chr9_133589790__NonTargetingControlGuideForHuman0352\", too.\n",
    "\n",
    ">(3) According to eqn.1, sj = medium (xij / x'i), I think the normalized count yij = xij / sj,  instead of yij = xij * sj.\n",
    "\n",
    "He then clarified point 1:\n",
    "\n",
    ">For our real data, we will have two replicates. Actually they are two independent experiment sets, which means experiment A(day3, day14, day28) and B(day3, day14, day28) but NOT the replicates at each time point like day3 (A,B), day14(A,B) and day28(A,B). Therefore, please always process each replicate independently. \n",
    "\n",
    ">For the question 1, i = gRNA pair and j = time point (day3, day14, day28). So x’i should be the geometric mean of the experiments (day3, day14 and day28) with gRNA pair i.\n",
    "\n",
    "In addition, Dr. Mali clarified point 2:\n",
    "\n",
    ">You are right -- position in the pairing does not matter: GeneA-GeneB or GeneB-GeneA do indeed refer to the same gene pair and there will be 9 such combinations total and hence are processed as a group.\n",
    "\n",
    "but\n",
    "\n",
    ">Just to clarify, in the original designs, I don't believe there is any pairing of the same gRNA-pair in both orientations. We did pair genes in both orientations, but never the same identical gRNA-pair.\n",
    "\n",
    "\n",
    "The input to the normalization will be the output of Module 1, which according to the specifications will include at least \"gRNA pair ID, targeted gene pair, raw counts\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"set-up-constants\"></a>\n",
    "\n",
    "### Set Up Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class data_file_format:\n",
    "    construct_id_header = \"construct_id\"\n",
    "    pair_separator = \"__\"\n",
    "    piece_separator = \"_\"\n",
    "    position_header_base = \"gene_position\"\n",
    "    position1_header = \"gene_position1\"\n",
    "    position2_header = \"gene_position2\"\n",
    "    gene_pair_header = \"gene_pair\"\n",
    "    num_expected_genes = 2\n",
    "    input_headers = [construct_id_header, \"expt1_day3\", \"expt2_day3\", \n",
    "                     \"expt1_day14\", \"expt2_day14\", \n",
    "                     \"expt1_day28\", \"expt2_day28\"]\n",
    "    general_headers = [construct_id_header, gene_pair_header, \n",
    "                      position1_header, position2_header]\n",
    "    experiment_set_prefixes = [\"expt1\", \"expt2\"]\n",
    "    # per discussion with Roman 03/22/2016, I expect every raw count file will \n",
    "    # include the same number of gRNA pair ids--the whole library.  \n",
    "    # Any gRNA pair id that was not sequenced will have a zero count.\n",
    "    expected_num_constructs = 24908\n",
    "    earliest_timept = \"day3\"    \n",
    "    negative_control_genes = ['NonTargetingControlGuideForHuman']\n",
    "    all_expts_prefix = \"all_expts\"\n",
    "    by_gene_pair_suffix = \"_by_gene_pair.csv\"\n",
    "    \n",
    "    def get_headers_for_experiment_set(column_names, experiment_set_prefix, \n",
    "                                       include_enum):\n",
    "        result = []\n",
    "        if include_enum == 0:\n",
    "            pass\n",
    "        elif include_enum == 1:\n",
    "            result = [x for x in data_file_format.general_headers]\n",
    "        elif include_enum == 2:\n",
    "            result = [x for x in data_file_format.general_headers \n",
    "                      if x != data_file_format.construct_id_header]\n",
    "        # end if\n",
    "        expt_specific_headers = [x for x in column_names \n",
    "                                 if x.startswith(experiment_set_prefix)]\n",
    "        result.extend(expt_specific_headers)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def get_headers_for_expt_timepoints(column_names, timepoint_suffix, \n",
    "                                        find_all_other_timepoints, \n",
    "                                        experiment_set_prefix):\n",
    "        timept_headers_for_expt_set = data_file_format.get_headers_for_experiment_set(\n",
    "            column_names, experiment_set_prefix, 0)\n",
    "        if find_all_other_timepoints:\n",
    "            result = [x for x in timept_headers_for_expt_set \n",
    "                      if not x.endswith(timepoint_suffix)]\n",
    "        else:\n",
    "            result = [x for x in timept_headers_for_expt_set \n",
    "                      if x.endswith(timepoint_suffix)]\n",
    "        return result\n",
    " \n",
    "        \n",
    "    def get_dataframe_for_expt(all_expts_dataframe, experiment_set_prefix, \n",
    "                                       include_general_enum):\n",
    "        copied_df = all_expts_dataframe.copy()\n",
    "        column_names = copied_df.columns.values\n",
    "        all_relevant_headers = data_file_format.get_headers_for_experiment_set(\n",
    "            column_names, experiment_set_prefix, include_general_enum)\n",
    "        data_frame = copied_df[all_relevant_headers]\n",
    "        return data_frame\n",
    "    \n",
    "\n",
    "def add_series_to_dataframe(dataframe, series, header):\n",
    "    dataframe.loc[:, header] = pandas.Series(series, \n",
    "        index=dataframe.index)        \n",
    "    \n",
    "\n",
    "# raw count column names\n",
    "g_grna_pair_id_header = \"gRNA_pair\"\n",
    "g_raw_counts_header = \"raw_counts\"\n",
    "g_geo_mean_header = \"geo_mean_across_expts\"\n",
    "\n",
    "# new column header/file text\n",
    "g_size_factor_txt = \"_size_factor\"\n",
    "g_norm_counts_txt = \"_norm_counts\"\n",
    "g_fold_change_txt = \"_fc\"\n",
    "g_log2_fold_change_txt = \"_log2fc\"\n",
    "g_log2_fitness_score_txt = \"_log2fitness\"\n",
    "g_log2_pi_score_txt = \"_log2pi_score\"\n",
    "g_norm_suffix = \"_norm.csv\"\n",
    "g_log2_fold_change_suffix = \"_log2_fc.csv\"\n",
    "g_pi_suffix = \"_pi_scores.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"set-up-helper-functions-for-normalization\"></a>\n",
    "\n",
    "### Set Up Helper Functions for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import glob\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "def get_file_path(file_type, expt_name):\n",
    "    return os.path.join(g_mod1_output_dir, \"{0}{1}\".format(expt_name, file_type))   \n",
    "\n",
    "\n",
    "get_norm_file_path = partial(get_file_path, g_norm_suffix)\n",
    "get_log2fc_file_path = partial(get_file_path, g_log2_fold_change_suffix)\n",
    "\n",
    "\n",
    "def get_norm_col_header(curr_day_header):\n",
    "    return \"{0}{1}\".format(curr_day_header,g_norm_counts_txt)\n",
    "\n",
    "\n",
    "def get_filepaths_from_wildcard(directory, wildcard_filename):\n",
    "    wildpath = os.path.join(directory, wildcard_filename)\n",
    "    return [x for x in glob.glob(wildpath)]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"normalize-across-all-experiment-sets\"></a>\n",
    "\n",
    "### Normalize Across All Experiment Sets\n",
    "\n",
    "Normalized counts are calculated per construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import scipy.stats.mstats\n",
    "\n",
    "    \n",
    "def load_all_expts(directory, raw_counts_filename, col_headers):\n",
    "    filepath = os.path.join(directory, raw_counts_filename) \n",
    "    all_expts_dataframe = pandas.read_table(filepath, names=col_headers, \n",
    "                                            skiprows=1)\n",
    "    return all_expts_dataframe\n",
    "\n",
    "\n",
    "def expand_info_from_construct_id(construct_row, file_format):\n",
    "    construct_id = construct_row[file_format.construct_id_header]\n",
    "    construct_id_pieces = construct_id.split(file_format.pair_separator)\n",
    "    \n",
    "    if len(construct_id_pieces) != file_format.num_expected_genes:\n",
    "        raise ValueError((\"Construct {0} split into {1} pieces\"\n",
    "                         \"rather than {2}\").format(construct_id, \n",
    "                         len(construct_id_pieces), \n",
    "                         file_format.num_expected_genes))\n",
    "        \n",
    "    results = []\n",
    "    for index in range(0, file_format.num_expected_genes):\n",
    "        gene_pieces = construct_id_pieces[index].split(\n",
    "            file_format.piece_separator)\n",
    "        gene = gene_pieces[0]\n",
    "        \n",
    "        # TODO: Double-check with customer if this is correct:\n",
    "        # if the \"gene\" name is for one of the non-targeting \n",
    "        # controls, compress to the control's name\n",
    "        for control_gene in file_format.negative_control_genes:\n",
    "            if gene.startswith(control_gene):\n",
    "                gene = control_gene\n",
    "                \n",
    "        results.append(gene)\n",
    "    \n",
    "    # Ensure that gene pairs are treated as combinations not\n",
    "    # permutations (order not important) by sorting gene list\n",
    "    # alphabetically\n",
    "    results.sort()\n",
    "    \n",
    "    gene_pair = file_format.pair_separator.join(results)\n",
    "    results.append(gene_pair)\n",
    "    return tuple(results)\n",
    "\n",
    "\n",
    "def expand_frame_with_gene_info(dataframe, file_format):    \n",
    "    row_expansion_func = lambda x: expand_info_from_construct_id(\n",
    "        x, file_format)\n",
    "    expanded_tuples_df = dataframe.apply(row_expansion_func, axis=1) \n",
    "    (dataframe[file_format.position1_header], \n",
    "     dataframe[file_format.position2_header], \n",
    "     dataframe[file_format.gene_pair_header]) = zip(*expanded_tuples_df)\n",
    "    \n",
    "\n",
    "def normalize_across_all_expts(all_expts_dataframe, file_format):\n",
    "    output_path = get_norm_file_path(file_format.all_expts_prefix)\n",
    "    days = [x for x in file_format.input_headers if x != file_format.construct_id_header]\n",
    "\n",
    "    # calculate geometric mean across all days for each \n",
    "    # gRNA pair id and add as new column\n",
    "    raw_counts_across_days = all_expts_dataframe[days]\n",
    "    # NB: 1 = apply to each row\n",
    "    geo_means = raw_counts_across_days.apply(\n",
    "        scipy.stats.mstats.gmean, axis=1)\n",
    "    add_series_to_dataframe(all_expts_dataframe, geo_means, g_geo_mean_header)\n",
    "\n",
    "    # for each day\n",
    "    for curr_day_header in days:\n",
    "        # calculate raw count value / geometric mean for all \n",
    "        # gRNA pair ids in day, then remove infinite and NaN values\n",
    "        raw_div_by_geo_mean = (all_expts_dataframe[curr_day_header] / \n",
    "                               all_expts_dataframe[g_geo_mean_header])   \n",
    "        temp = raw_div_by_geo_mean.replace([numpy.inf, -numpy.inf], \n",
    "                                           numpy.nan)\n",
    "        raw_div_by_geo_mean = temp.dropna()\n",
    "\n",
    "        # calculate size factor for day as median of above\n",
    "        # NB: 0 = apply to each column\n",
    "        size_factor = raw_div_by_geo_mean.median(axis=0)             \n",
    "\n",
    "        # add new column holding size factor for day \n",
    "        # (same for all gRNA pair ids)         \n",
    "        size_factor_vector = [size_factor for x in range(\n",
    "                0, file_format.expected_num_constructs)]\n",
    "        size_factor_header = \"{0}{1}\".format(curr_day_header, \n",
    "                                             g_size_factor_txt)\n",
    "        add_series_to_dataframe(all_expts_dataframe, size_factor_vector, \n",
    "                                size_factor_header)\n",
    "\n",
    "        # vector-calculate normalized count value for all gRNA pair ids \n",
    "        # in this day as raw count value for gRNA pair id in this day \n",
    "        # divided by size factor for day, add as new column\n",
    "        norm_counts = (all_expts_dataframe[curr_day_header] / \n",
    "                       all_expts_dataframe[size_factor_header])\n",
    "        norm_header = get_norm_col_header(curr_day_header)\n",
    "        add_series_to_dataframe(all_expts_dataframe, norm_counts, \n",
    "                                norm_header)        \n",
    "\n",
    "        all_expts_dataframe.to_csv(output_path, index=False)\n",
    "        \n",
    "\n",
    "def normalize_all_expts(directory, raw_counts_filename):\n",
    "    expts_dataframe = load_all_expts(directory, raw_counts_filename, \n",
    "                                     data_file_format.input_headers)\n",
    "    expand_frame_with_gene_info(expts_dataframe, data_file_format)\n",
    "    normalize_across_all_expts(expts_dataframe, data_file_format)\n",
    "    \n",
    "normalize_all_expts(g_mod1_output_dir, \"prashant_all_counts.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"calculate-fold-changes\"></a>\n",
    "\n",
    "## Calculate Fold Changes\n",
    "\n",
    "methods.docx specifies that fold changes should be calculated by the following approach:\n",
    "![](images/2016-03-21_11.50.44.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also received the following clarifications from Dr. Mali on two minor methods questions:\n",
    "\n",
    "1. The methods specify \"These fold changes are log-transformed”; do you want log base 2 or log base 10 transformation?  The former is more common for biological screening applications.\n",
    "    *  log base 2 is preferred.\n",
    "2. Do you want the average of the log fold changes for the constructs in the gene pair, or the log of the average fold change for constructs in a gene pair?  Again, I would anticipate the former (see http://www.experts-exchange.com/questions/22667100/log-transformation-of-average-or-average-of-log-transformation.html for relevant reasoning).\n",
    "    * average of the log fold changes for the constructs in the gene pair is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"calculate-fold-change-and-log-fold-change-between-timepoints\"></a>\n",
    "\n",
    "### Calculate Fold Change and Log2 Fold Change Between Timepoints\n",
    "\n",
    "These values are calculated per construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "def input_plus_one(x):\n",
    "    return x+1\n",
    "\n",
    "\n",
    "def get_norm_plus_one_series(data_frame, source_token):\n",
    "    # get normalized count + 1 for input source (a timept or plasmid)\n",
    "    norm_source_token = get_norm_col_header(source_token)\n",
    "    return data_frame[norm_source_token].apply(input_plus_one)\n",
    "\n",
    "    \n",
    "def add_fold_change_series(dataframe, numerator_series, numerator_name, \n",
    "                           denominator_series, denominator_name):\n",
    "    fold_change = (numerator_series / denominator_series)\n",
    "    fold_change_header = \"{0}_vs_{1}{2}\".format(numerator_name, \n",
    "                                                \n",
    "                                                \n",
    "        denominator_name, g_fold_change_txt)        \n",
    "    add_series_to_dataframe(dataframe, fold_change, fold_change_header)\n",
    "    return fold_change, fold_change_header\n",
    "  \n",
    "    \n",
    "def add_log2fc_series(dataframe, fc_series, fc_header):\n",
    "    log2_fold_change = fc_series.apply(numpy.log2)   \n",
    "    log2_fold_change_header = fc_header.replace(g_fold_change_txt, \n",
    "        g_log2_fold_change_txt)\n",
    "    add_series_to_dataframe(dataframe, log2_fold_change, \n",
    "        log2_fold_change_header)   \n",
    "    \n",
    "    \n",
    "def add_fold_change_and_log2fc(dataframe, numerator_series, numerator_name, \n",
    "                           denominator_series, denominator_name):\n",
    "    fc_series, fc_header = add_fold_change_series(dataframe, \n",
    "        numerator_series, numerator_name, denominator_series, denominator_name)\n",
    "    add_log2fc_series(dataframe, fc_series, fc_header)\n",
    "    \n",
    "    \n",
    "def calculate_fold_changes_across_days(file_format):\n",
    "    norm_csv_path = get_norm_file_path(file_format.all_expts_prefix)   \n",
    "    output_path = get_log2fc_file_path(file_format.all_expts_prefix)\n",
    "    all_expts_dataframe = pandas.read_csv(norm_csv_path)\n",
    "    columns = file_format.input_headers\n",
    "    \n",
    "    for curr_expt_set_prefix in file_format.experiment_set_prefixes:\n",
    "        earliest_timept_header = file_format.get_headers_for_expt_timepoints(\n",
    "            columns, file_format.earliest_timept, False, curr_expt_set_prefix)[0]\n",
    "        later_timept_headers = file_format.get_headers_for_expt_timepoints(\n",
    "            columns, file_format.earliest_timept, True, curr_expt_set_prefix)\n",
    "        earliest_timept_norm_plus_one = get_norm_plus_one_series(\n",
    "            all_expts_dataframe, earliest_timept_header)\n",
    "\n",
    "        for curr_later_timept in later_timept_headers:\n",
    "            # calculate fold change and log2 fold change for each gRNA pair, \n",
    "            # and add to data frame\n",
    "            later_timept_norm_plus_one = get_norm_plus_one_series(\n",
    "                all_expts_dataframe, curr_later_timept)\n",
    "            add_fold_change_and_log2fc(all_expts_dataframe, \n",
    "                later_timept_norm_plus_one, curr_later_timept, \n",
    "                earliest_timept_norm_plus_one, earliest_timept_header)\n",
    "\n",
    "    all_expts_dataframe.to_csv(output_path, index=False)\n",
    "        \n",
    "calculate_fold_changes_across_days(data_file_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"calculate-fold-change-and-log-fold-change-against-plasmid\"></a>\n",
    "\n",
    "### Calculate Fold Change and Log2 Fold Change Against Plasmid\n",
    "\n",
    "The workflow.pdf requests \"Fold change VS plasmid: d3/plasmid, d14/plasmid and d28/plasmid\".  As above, these are calculated per construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Roman opines that if experiment day values are being compared to plasmid values, \n",
    "# then plasmid values must be included in the normalization step.\n",
    "# I want to ensure the customer understand this before modifying the normalization\n",
    "# code.\n",
    "\n",
    "def calculate_fold_changes_against_plasmid(file_format):\n",
    "    all_expts_dataframe = pandas.Dataframe([])  # TODO: GET REAL NORMALIZED DAY DATA\n",
    "    plasmid_norm_counts = pandas.Series([])  # TODO: GET REAL NORMALIZED? PLASMID DATA\n",
    "    plasmid_norm_plus_one = get_norm_plus_one_series(data_frame, source_token)\n",
    "    \n",
    "    # TODO: Find out how customer wants plasmid fold changes to be output--same file\n",
    "    # as other fold-changes?  Different?  What downstream use planned?\n",
    "    # This will affect how I grab the normalized day data (e.g., grouped by expt or not)\n",
    "    \n",
    "# TODO: fill out plasmid fold change calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"calculate-fitness-and-pi-scores\"></a>\n",
    "\n",
    "## Calculate Fitness and Pi Scores\n",
    "\n",
    "Fitness scores are calculated per gene.  Pi scores are calculated per construct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "def get_relevant_col_names(col_name_suffix, data_frame):\n",
    "    col_names = data_frame.columns.values    \n",
    "    relevant_col_names = [x for x in col_names if x.endswith(\n",
    "            col_name_suffix)]\n",
    "    return relevant_col_names\n",
    "\n",
    "\n",
    "get_fc_col_names = partial(get_relevant_col_names, g_log2_fold_change_txt)\n",
    "get_pi_col_names = partial(get_relevant_col_names, g_log2_pi_score_txt)\n",
    "\n",
    "\n",
    "def get_indexes_for_id(id, dataframe, list_of_col_headers):\n",
    "    filters = [dataframe[x] == id for x in list_of_col_headers]\n",
    "    indexes = numpy.any(filters, axis=0)\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def get_data_for_gene(curr_gene, dataframe, data_col_name, position_cols_list):\n",
    "    indexes_for_gene = get_indexes_for_id(curr_gene, dataframe, \n",
    "                                          position_cols_list)\n",
    "    dataframe_for_curr_gene = dataframe[indexes_for_gene] \n",
    "    return dataframe_for_curr_gene[data_col_name]\n",
    "\n",
    "\n",
    "def get_median_for_gene(gene_name, dataframe, data_col_name, position_cols_list):\n",
    "    data_for_gene = get_data_for_gene(gene_name, dataframe, data_col_name, \n",
    "                                      position_cols_list)\n",
    "    return data_for_gene.median()\n",
    "        \n",
    "    \n",
    "def get_half_medians_for_gene_col(gene_series, dataframe, data_col_name, \n",
    "                                  position_cols_list):\n",
    "    custom_median_func = lambda x: get_median_for_gene(x, dataframe, \n",
    "                                                       data_col_name, \n",
    "                                                       position_cols_list)\n",
    "    medians_by_gene = gene_series.apply(custom_median_func) \n",
    "    medians_by_gene_series = pandas.Series(medians_by_gene, \n",
    "                                           index=gene_series.index)\n",
    "    return 0.5 * medians_by_gene_series\n",
    "\n",
    "\n",
    "def get_unique_vals_in_column(dataframe, col_name):\n",
    "    uniques_array = dataframe[col_name].unique()\n",
    "    uniques_series = pandas.Series(uniques_array, index=uniques_array)    \n",
    "    return uniques_series\n",
    "    \n",
    "    \n",
    "def compute_residual(row, data_col_name, other_position_header, \n",
    "                     genes_main_effects):\n",
    "    raw_data = row[data_col_name]\n",
    "    other_gene = row[other_position_header]\n",
    "    other_main_effect = genes_main_effects[other_gene]\n",
    "    residual = raw_data - other_main_effect\n",
    "    return residual\n",
    "    \n",
    "    \n",
    "def compute_residuals(dataframe, data_col_name, other_position_header, \n",
    "                      other_genes_main_effects):\n",
    "    custom_residuals_func = lambda x: compute_residual(x, data_col_name, \n",
    "                                                       other_position_header, \n",
    "                                                       other_genes_main_effects)\n",
    "    # NB: 1 = apply to each row\n",
    "    residuals = dataframe.apply(custom_residuals_func, axis=1)  \n",
    "    return residuals\n",
    "\n",
    "\n",
    "def get_residuals_median_for_gene(gene_name, residuals_series, index_frame, \n",
    "                                  focus_position_header, main_effects):\n",
    "    indexes_for_gene = get_indexes_for_id(gene_name, index_frame, \n",
    "                                          [focus_position_header])\n",
    "    residuals_for_gene = residuals_series[indexes_for_gene]\n",
    "    median_residual = residuals_for_gene.median()\n",
    "    main_effects[gene_name] = median_residual\n",
    "    \n",
    "\n",
    "def iterate_main_effects(dataframe, data_col_name, focus_position_header, \n",
    "                         other_position_header, main_effects):\n",
    "    residuals = compute_residuals(dataframe, data_col_name, \n",
    "                                  other_position_header, main_effects)\n",
    "    unique_genes_in_focus_pos = get_unique_vals_in_column(dataframe, \n",
    "                                                          focus_position_header)\n",
    "    custom_residuals_median_func = lambda x: get_residuals_median_for_gene(x, \n",
    "        residuals, dataframe, focus_position_header, main_effects)\n",
    "    unique_genes_in_focus_pos.apply(custom_residuals_median_func)   \n",
    "    \n",
    "    \n",
    "def get_base_main_effects(unique_genes_series, data_frame, data_col_header, \n",
    "                          position1_header, position2_header):\n",
    "    main_effects_by_gene = get_half_medians_for_gene_col(unique_genes_series, \n",
    "        data_frame, data_col_header, [position1_header, position2_header])\n",
    "    \n",
    "    for _ in range(0,20):\n",
    "        iterate_main_effects(data_frame, data_col_header, position1_header, \n",
    "                             position2_header, main_effects_by_gene)\n",
    "        iterate_main_effects(data_frame, data_col_header, position2_header, \n",
    "                             position1_header, main_effects_by_gene)\n",
    "    \n",
    "    return main_effects_by_gene\n",
    "\n",
    "\n",
    "def get_control_mean(unique_genes_in_focus_pos, negative_control_genes, \n",
    "                     main_effects):\n",
    "    present_neg_controls = unique_genes_in_focus_pos[\n",
    "        unique_genes_in_focus_pos.isin(negative_control_genes)]\n",
    "    if len(present_neg_controls) < 1:    \n",
    "        raise ValueError(\"No negative controls found in among genes {0}\"\n",
    "                         .format(unique_genes_in_focus_pos))\n",
    "    main_effects_for_present_negs = main_effects[present_neg_controls]\n",
    "    return main_effects_for_present_negs.mean()\n",
    "\n",
    "    \n",
    "def normalize_main_effect(gene_index, control_mean, main_effects):\n",
    "    base_main_effect = main_effects[gene_index]\n",
    "    normalized_main_effect = base_main_effect - control_mean\n",
    "    main_effects[gene_index] = normalized_main_effect\n",
    "    \n",
    "\n",
    "def subtract_control_mean_from_main_effects(dataframe, focus_position_header, \n",
    "                                            neg_control_genes, main_effects):\n",
    "    unique_genes_in_focus_pos = get_unique_vals_in_column(dataframe, \n",
    "                                                          focus_position_header)\n",
    "    control_mean = get_control_mean(unique_genes_in_focus_pos, neg_control_genes, \n",
    "                                    main_effects)\n",
    "    custom_normalize_func = lambda x: normalize_main_effect(x, control_mean, \n",
    "                                                            main_effects)\n",
    "    unique_genes_in_focus_pos.apply(custom_normalize_func)  \n",
    "    return control_mean\n",
    "\n",
    "\n",
    "def calculate_pi_score(row, main_effects, sum_control_means, data_col_header, \n",
    "                       position1_header, position2_header):\n",
    "    position1_gene_id = row[position1_header]\n",
    "    position2_gene_id = row[position2_header]\n",
    "    real_data = row[data_col_header]\n",
    "    \n",
    "    # model = main effect for gene in position 1 + \n",
    "    # main effect for gene in position 2 + sum of neg means    \n",
    "    model_prediction = (main_effects[position1_gene_id] \n",
    "                        + main_effects[position2_gene_id] + sum_control_means)\n",
    "    pi_score = real_data - model_prediction\n",
    "    return pi_score\n",
    "\n",
    "\n",
    "def calculate_pi_scores_for_expt(dataframe, main_effects, sum_control_means, \n",
    "                                 data_col_header, position1_header, \n",
    "                                 position2_header):\n",
    "    custom_pi_score_func = lambda x: calculate_pi_score(x, main_effects, \n",
    "        sum_control_means,data_col_header, position1_header, position2_header)\n",
    "    # NB: 1 = rows\n",
    "    pi_scores = dataframe.apply(custom_pi_score_func, axis=1)\n",
    "    return pi_scores\n",
    "    \n",
    "    \n",
    "def calculate_pi_scores(file_format):\n",
    "    log2fc_csv_path = get_log2fc_file_path(file_format.all_expts_prefix)     \n",
    "    pi_output_path = get_file_path(g_pi_suffix, file_format.all_expts_prefix)\n",
    "    fitness_output_path = get_file_path(\"_fitness_scores.csv\", \n",
    "                                        file_format.all_expts_prefix)\n",
    "    all_expts_dataframe = pandas.read_csv(log2fc_csv_path)\n",
    "    \n",
    "    vals_in_position_cols = all_expts_dataframe[[file_format.position1_header, \n",
    "        file_format.position2_header]].values.ravel()\n",
    "    unique_genes = pandas.Series(vals_in_position_cols).unique()\n",
    "    unique_genes_series = pandas.Series(unique_genes, index=unique_genes)\n",
    "    fitness_scores_df = unique_genes_series.to_frame(name=\"gene\")\n",
    "    \n",
    "    for curr_expt_set_prefix in file_format.experiment_set_prefixes:\n",
    "        data_frame = file_format.get_dataframe_for_expt(all_expts_dataframe, \n",
    "            curr_expt_set_prefix, 2)\n",
    "        \n",
    "        data_col_headers =  get_fc_col_names(data_frame)   \n",
    "        for data_col_header in data_col_headers:\n",
    "            main_effects = get_base_main_effects(unique_genes_series, \n",
    "                data_frame, data_col_header, file_format.position1_header, \n",
    "                file_format.position2_header)           \n",
    "            \n",
    "            # test values: [4,11,1062,1068]\n",
    "            negative_control_genes = file_format.negative_control_genes\n",
    "            position1_control_mean = subtract_control_mean_from_main_effects(\n",
    "                data_frame, file_format.position1_header, \n",
    "                negative_control_genes, main_effects)\n",
    "            position2_control_mean = subtract_control_mean_from_main_effects(\n",
    "                data_frame, file_format.position2_header, \n",
    "                negative_control_genes, main_effects)\n",
    "            \n",
    "            fitness_score_header = data_col_header.replace(g_log2_fold_change_txt,\n",
    "                g_log2_fitness_score_txt)\n",
    "            add_series_to_dataframe(fitness_scores_df, main_effects, \n",
    "                                    fitness_score_header)              \n",
    "            \n",
    "            sum_control_means = position1_control_mean + position2_control_mean\n",
    "\n",
    "            pi_scores_for_expt = calculate_pi_scores_for_expt(data_frame, \n",
    "                                        main_effects, sum_control_means, \n",
    "                                        data_col_header, file_format.position1_header,  \n",
    "                                        file_format.position2_header)\n",
    "            \n",
    "            pi_score_header = data_col_header.replace(g_log2_fold_change_txt,\n",
    "                g_log2_pi_score_txt)            \n",
    "            add_series_to_dataframe(all_expts_dataframe, pi_scores_for_expt, \n",
    "                                    pi_score_header)\n",
    "            \n",
    "    all_expts_dataframe.to_csv(pi_output_path, index=False)\n",
    "    \n",
    "    # NB: pi(ab) = f(ab) - f(a) - f(b) - controls\n",
    "    # where f values are log2-transformed fitness scores\n",
    "    # Thus, the gene-pair \"fitness scores\" are actually just the contents\n",
    "    # of the <expt>_avg_log2fc_by_gene_pair file\n",
    "    # And the fitness scores of the individual genes are the main effects\n",
    "    fitness_scores_df.to_csv(fitness_output_path, index=False)\n",
    "        \n",
    "calculate_pi_scores(data_file_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name=\"calculate-averages-and-p-values-for-gene-pair-metrics\"></a>\n",
    "\n",
    "### Calculate Averages and P-Values for Gene Pair Metrics\n",
    "\n",
    "These values are calculated per gene pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def get_p_vals_from_tuples(t_and_p_tuple_series):\n",
    "    custom_extract_func = lambda x: x[1]\n",
    "    # NB: 1 = apply to each row\n",
    "    p_vals_series = t_and_p_tuple_series.apply(custom_extract_func)  \n",
    "    return p_vals_series\n",
    "\n",
    "\n",
    "def calculate_means_and_ps(all_expts_dataframe, file_format):\n",
    "    relevant_col_functions = [get_fc_col_names, get_pi_col_names]\n",
    "    calculated_series = []\n",
    "    \n",
    "    for curr_expt_set_prefix in file_format.experiment_set_prefixes:\n",
    "        data_frame = file_format.get_dataframe_for_expt(all_expts_dataframe, \n",
    "            curr_expt_set_prefix, 1)\n",
    "        grouped_by_gene_pair = data_frame.groupby([file_format.gene_pair_header, \n",
    "                                                   file_format.position1_header, \n",
    "                                                   file_format.position2_header])\n",
    "\n",
    "        for relevant_cols_func in relevant_col_functions:\n",
    "            relevant_col_names = relevant_cols_func(data_frame)\n",
    "            for curr_col in relevant_col_names:\n",
    "                col_vals_for_groups = grouped_by_gene_pair[curr_col]\n",
    "                stats_test_func = lambda x: stats.ttest_1samp(x, 0)\n",
    "\n",
    "                t_stat_and_p_tuples = col_vals_for_groups.aggregate(\n",
    "                    stats_test_func)\n",
    "                new_p_series = get_p_vals_from_tuples(t_stat_and_p_tuples)\n",
    "                new_p_series.name =  curr_col + \"_p\"\n",
    "                calculated_series.append(new_p_series)\n",
    "\n",
    "                new_mean_series = col_vals_for_groups.mean()\n",
    "                new_mean_series.name =  curr_col + \"_mean\"\n",
    "                calculated_series.append(new_mean_series)\n",
    "\n",
    "    new_data_frame = pandas.concat(calculated_series, axis=1)\n",
    "    return new_data_frame\n",
    "\n",
    "\n",
    "def calculate_log2fc_and_pi_mean_and_p(file_format):\n",
    "    pi_scores_path = get_file_path(g_pi_suffix, \n",
    "                                   file_format.all_expts_prefix)  \n",
    "    all_expts_dataframe = pandas.read_csv(pi_scores_path)\n",
    "    output_path = get_file_path(file_format.by_gene_pair_suffix, \n",
    "                                file_format.all_expts_prefix)\n",
    "\n",
    "    new_data_frame = calculate_means_and_ps(all_expts_dataframe, \n",
    "                                            file_format)\n",
    "    new_data_frame.to_csv(output_path, header=True, \n",
    "                          index_label=[file_format.gene_pair_header,\n",
    "                          file_format.position1_header, \n",
    "                          file_format.position2_header])        \n",
    "        \n",
    "calculate_log2fc_and_pi_mean_and_p(data_file_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name = \"outstanding-questions\"></a>\n",
    "    \n",
    "## Outstanding Questions\n",
    "\n",
    "<a name = \"aggregated-normalization\"></a>\n",
    "\n",
    "### Aggregated Normalization\n",
    "\n",
    "The customer had indicated data will be generated several different times; we need to know more about the source and use of these different data groupings.  If they will be treated independently, then they can each be normalized (and subsequently analyzed) separately.  However, if they will be compared, then Roman considers that they should all be normalized together.  This seems at odds with the customer's goal of analyzing the data as it becomes available.\n",
    "\n",
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "<a name = \"non-targeting-control-collapse\"></a>\n",
    "\n",
    "### Non-Targeting Control Collapse\n",
    "\n",
    "Double-check with customer if this is correct: if the \"gene\" name is for one of the non-targeting controls, compress to the control's name.\n",
    "\n",
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "### Plasmid Fold Changes\n",
    "\n",
    "<a name = \"plasmid-fold-changes\"></a>\n",
    "\n",
    "Roman opines that if experiment day values are being compared to plasmid values, then plasmid values must be included in the normalization step.  I want to ensure the customer understand this before modifying the normalization\n",
    "code.\n",
    "\n",
    "Also: how does customer wants plasmid fold changes to be output--same file as other fold-changes?  Different?  What downstream use planned? This will affect how I grab the normalized day data (e.g., grouped by expt or not).\n",
    "\n",
    "[Table of Contents](#table-of-contents)\n",
    "    \n",
    "<a name = \"fitness-score-p-values\"></a>    \n",
    "    \n",
    "### Fitness Score P-Values\n",
    "\n",
    "Need clarification from customer on how they want p-values calculated for \n",
    "fitness scores. Same way as for pi scores: 1-sample t-test on ... what\n",
    "distribution?  Combination (median, rather than mean) is done inside\n",
    "get_residuals_median_for_gene, which is ITERATED 20 times, although\n",
    "the number of constructs containing the gene is the same every time ... \n",
    "if we did t-test at this stage, would use residuals_for_gene as \n",
    "distribution to test as different from zero?  Do we just test after final\n",
    "iteration?  What about fact that the base main effects (from the \n",
    "median of residuals) have the control means *subtracted* from them later \n",
    "(long after combination to single effect per gene)?\n",
    "\n",
    "Or ... is it possible they want p-values on fitness scores of gene *pairs*,\n",
    "directly analogous to p-values on pi values of gene pairs?  That's easy,\n",
    "so implemented it just in case that's what they want.\n",
    "\n",
    "[Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
